{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9060eb35",
   "metadata": {},
   "source": [
    "# Lesson 10: Creating and Modifying Tables in PostgreSQL\n",
    "\n",
    "This notebook covers essential SQL operations for database table management:\n",
    "- Creating tables\n",
    "- Inserting data\n",
    "- Updating data\n",
    "- Importing data from CSV files\n",
    "- Working with LucidChart exported SQL\n",
    "\n",
    "**Database Location:** `/workspaces/Fall2025-MS3083-Base_Template/databases/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2726091",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Connect to PostgreSQL\n",
    "\n",
    "First, we'll import the necessary libraries and establish a connection to PostgreSQL.\n",
    "\n",
    "**Note:** This notebook is configured to use the `student` PostgreSQL user that's set up in your dev container. If you need to use a different user, update the `DB_USER` variable in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83086e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'lesson10_demo' already exists.\n",
      "Connected to database: lesson10_demo\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import psycopg2  # PostgreSQL adapter for Python - allows direct database connections\n",
    "import pandas as pd  # Data manipulation library - makes working with tables easy\n",
    "from sqlalchemy import create_engine, text  # SQLAlchemy - modern database toolkit for Python\n",
    "import os  # Operating system interface - for file path operations\n",
    "\n",
    "# Database connection parameters\n",
    "DB_NAME = \"lesson10_demo\"  # Name of the database we'll create/connect to\n",
    "DB_USER = \"student\"  # PostgreSQL username (changed from \"postgres\" to match your system)\n",
    "DB_PASSWORD = \"\"  # Password (empty for local connections in this dev container)\n",
    "DB_HOST = \"localhost\"  # Server location (localhost = this machine)\n",
    "DB_PORT = \"5432\"  # PostgreSQL default port\n",
    "\n",
    "# Create connection string for SQLAlchemy\n",
    "# Format: postgresql://username:password@host:port/database\n",
    "connection_string = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# Create database if it doesn't exist\n",
    "try:\n",
    "    # Connect to the default 'postgres' database first (always exists)\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",  # Connect to default database\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    conn.autocommit = True  # Enable autocommit mode (changes happen immediately)\n",
    "    cursor = conn.cursor()  # Create cursor object to execute SQL commands\n",
    "    \n",
    "    # Check if our target database already exists\n",
    "    cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{DB_NAME}'\")\n",
    "    exists = cursor.fetchone()  # Get the result (None if database doesn't exist)\n",
    "    \n",
    "    if not exists:\n",
    "        # Database doesn't exist, so create it\n",
    "        cursor.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "        print(f\"Database '{DB_NAME}' created successfully!\")\n",
    "    else:\n",
    "        # Database already exists\n",
    "        print(f\"Database '{DB_NAME}' already exists.\")\n",
    "    \n",
    "    # Clean up: close cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    # If anything goes wrong, print the error message\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Now connect to our new database using SQLAlchemy\n",
    "# SQLAlchemy engine manages connections and provides modern database features\n",
    "engine = create_engine(connection_string)\n",
    "print(f\"Connected to database: {DB_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5a63a",
   "metadata": {},
   "source": [
    "## 1. Creating a Table from Scratch\n",
    "\n",
    "In this section, we'll create a `students` table with various column types commonly used in databases.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **SERIAL**: Auto-incrementing integer, perfect for ID columns\n",
    "- **PRIMARY KEY**: Uniquely identifies each row\n",
    "- **VARCHAR(n)**: Variable-length text up to n characters\n",
    "- **NOT NULL**: Field must have a value\n",
    "- **UNIQUE**: No two rows can have the same value\n",
    "- **DATE/TIMESTAMP**: Store dates and times\n",
    "- **DECIMAL(p,s)**: Numbers with exact precision (p=total digits, s=decimal places)\n",
    "- **CHECK**: Validates data meets certain conditions\n",
    "- **DEFAULT**: Provides automatic values if none specified\n",
    "- **BOOLEAN**: True/False values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc439ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'students' created successfully!\n",
      "\n",
      "Table structure:\n",
      "       column_name                    data_type  character_maximum_length  \\\n",
      "0       student_id                      integer                       NaN   \n",
      "1       first_name            character varying                      50.0   \n",
      "2        last_name            character varying                      50.0   \n",
      "3            email            character varying                     100.0   \n",
      "4  enrollment_date                         date                       NaN   \n",
      "5              gpa                      numeric                       NaN   \n",
      "6        is_active                      boolean                       NaN   \n",
      "7       created_at  timestamp without time zone                       NaN   \n",
      "\n",
      "  is_nullable  \n",
      "0          NO  \n",
      "1          NO  \n",
      "2          NO  \n",
      "3         YES  \n",
      "4         YES  \n",
      "5         YES  \n",
      "6         YES  \n",
      "7         YES  \n"
     ]
    }
   ],
   "source": [
    "# Define the SQL statement to create a students table\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS students (\n",
    "    student_id SERIAL PRIMARY KEY,                                    -- Auto-incrementing ID (1, 2, 3...)\n",
    "    first_name VARCHAR(50) NOT NULL,                                  -- First name (required, max 50 chars)\n",
    "    last_name VARCHAR(50) NOT NULL,                                   -- Last name (required, max 50 chars)\n",
    "    email VARCHAR(100) UNIQUE,                                        -- Email (must be unique across all students)\n",
    "    enrollment_date DATE DEFAULT CURRENT_DATE,                        -- Date enrolled (defaults to today)\n",
    "    gpa DECIMAL(3,2) CHECK (gpa >= 0.0 AND gpa <= 4.0),              -- GPA (2 decimal places, must be 0.0-4.0)\n",
    "    is_active BOOLEAN DEFAULT TRUE,                                   -- Active status (defaults to true)\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP                    -- When record was created\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the CREATE TABLE statement\n",
    "with engine.connect() as connection:\n",
    "    # text() wraps the SQL string so SQLAlchemy 2.0+ can execute it\n",
    "    connection.execute(text(create_table_sql))\n",
    "    connection.commit()  # Save the changes to the database\n",
    "    print(\"Table 'students' created successfully!\")\n",
    "\n",
    "# Verify the table structure by querying PostgreSQL's information schema\n",
    "query = \"\"\"\n",
    "SELECT column_name, data_type, character_maximum_length, is_nullable\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'students'\n",
    "ORDER BY ordinal_position;\n",
    "\"\"\"\n",
    "\n",
    "# Use pandas to read the query results into a DataFrame for easy viewing\n",
    "df = pd.read_sql(query, engine)\n",
    "print(\"\\nTable structure:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88287ee",
   "metadata": {},
   "source": [
    "## 2. Inserting Data into a Table\n",
    "\n",
    "Now that we have a table, let's add data to it. There are several ways to insert data.\n",
    "\n",
    "### Method 1: Single Row Insert\n",
    "\n",
    "This method inserts one row at a time. It's useful when:\n",
    "- Adding individual records\n",
    "- Getting data from user input\n",
    "- You need to insert records one at a time\n",
    "\n",
    "**Syntax:** `INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single row inserted successfully!\n",
      "\n",
      "Current data in students table:\n",
      "   student_id first_name last_name                 email enrollment_date  \\\n",
      "0           1       John       Doe  john.doe@example.com      2025-10-30   \n",
      "\n",
      "    gpa  is_active                 created_at  \n",
      "0  3.75       True 2025-10-30 02:50:15.348302  \n"
     ]
    }
   ],
   "source": [
    "# Define SQL to insert a single student record\n",
    "insert_single_sql = \"\"\"\n",
    "INSERT INTO students (first_name, last_name, email, gpa)\n",
    "VALUES ('John', 'Doe', 'john.doe@example.com', 3.75);\n",
    "\"\"\"\n",
    "# Note: We don't specify student_id (auto-generated), enrollment_date, is_active, \n",
    "# or created_at (they use DEFAULT values)\n",
    "\n",
    "# Execute the INSERT statement\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(insert_single_sql))  # text() wraps the SQL string\n",
    "    connection.commit()  # Commit the transaction to save the data\n",
    "    print(\"Single row inserted successfully!\")\n",
    "\n",
    "# Query the table to see our inserted data\n",
    "df = pd.read_sql(\"SELECT * FROM students;\", engine)\n",
    "print(\"\\nCurrent data in students table:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89553a5c",
   "metadata": {},
   "source": [
    "### Method 2: Multiple Row Insert\n",
    "\n",
    "This method inserts multiple rows in a single SQL statement. It's more efficient than multiple single-row inserts because:\n",
    "- It reduces the number of round trips to the database\n",
    "- It's faster for bulk data insertion\n",
    "- It uses fewer resources\n",
    "\n",
    "**Syntax:** `INSERT INTO table_name (columns...) VALUES (row1...), (row2...), (row3...);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b759bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple rows inserted successfully!\n",
      "\n",
      "All students:\n",
      "   student_id first_name last_name                       email  \\\n",
      "0           1       John       Doe        john.doe@example.com   \n",
      "1           2       Jane     Smith      jane.smith@example.com   \n",
      "2           3        Bob   Johnson     bob.johnson@example.com   \n",
      "3           4      Alice  Williams  alice.williams@example.com   \n",
      "4           5    Charlie     Brown   charlie.brown@example.com   \n",
      "\n",
      "  enrollment_date   gpa  is_active                 created_at  \n",
      "0      2025-10-30  3.75       True 2025-10-30 02:50:15.348302  \n",
      "1      2025-10-30  3.90       True 2025-10-30 02:50:15.361754  \n",
      "2      2025-10-30  3.45       True 2025-10-30 02:50:15.361754  \n",
      "3      2025-10-30  3.85       True 2025-10-30 02:50:15.361754  \n",
      "4      2025-10-30  3.20       True 2025-10-30 02:50:15.361754  \n"
     ]
    }
   ],
   "source": [
    "# Define SQL to insert multiple student records at once\n",
    "insert_multiple_sql = \"\"\"\n",
    "INSERT INTO students (first_name, last_name, email, gpa) VALUES\n",
    "    ('Jane', 'Smith', 'jane.smith@example.com', 3.90),        -- Student 1\n",
    "    ('Bob', 'Johnson', 'bob.johnson@example.com', 3.45),      -- Student 2\n",
    "    ('Alice', 'Williams', 'alice.williams@example.com', 3.85), -- Student 3\n",
    "    ('Charlie', 'Brown', 'charlie.brown@example.com', 3.20);  -- Student 4\n",
    "\"\"\"\n",
    "# Each row is separated by a comma, last row ends with semicolon\n",
    "\n",
    "# Execute the multi-row INSERT statement\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(insert_multiple_sql))\n",
    "    connection.commit()  # Save all rows at once\n",
    "    print(\"Multiple rows inserted successfully!\")\n",
    "\n",
    "# Query all students, ordered by ID\n",
    "df = pd.read_sql(\"SELECT * FROM students ORDER BY student_id;\", engine)\n",
    "print(\"\\nAll students:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e453b73",
   "metadata": {},
   "source": [
    "## 3. Updating Data in a Table\n",
    "\n",
    "The UPDATE statement modifies existing records in a table. **ALWAYS use a WHERE clause** to specify which rows to update, or you'll update ALL rows!\n",
    "\n",
    "**Syntax:** `UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition;`\n",
    "\n",
    "**Important:** \n",
    "- Without WHERE, ALL rows will be updated\n",
    "- Use WHERE to target specific rows\n",
    "- You can update multiple columns at once\n",
    "- The UPDATE returns the number of rows affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 1 row(s)\n",
      "\n",
      "Updated student record:\n",
      "   student_id first_name last_name                 email enrollment_date  \\\n",
      "0           1       John       Doe  john.doe@example.com      2025-10-30   \n",
      "\n",
      "    gpa  is_active                 created_at  \n",
      "0  3.95       True 2025-10-30 02:50:15.348302  \n"
     ]
    }
   ],
   "source": [
    "# Define SQL to update a specific student's GPA\n",
    "update_sql = \"\"\"\n",
    "UPDATE students                                  -- Table to update\n",
    "SET gpa = 3.95                                   -- Set GPA to new value\n",
    "WHERE email = 'john.doe@example.com';            -- Only update John Doe's record\n",
    "\"\"\"\n",
    "# The WHERE clause is crucial - without it, ALL students would get gpa = 3.95!\n",
    "\n",
    "# Execute the UPDATE statement\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(update_sql))\n",
    "    connection.commit()  # Commit the changes\n",
    "    # result.rowcount tells us how many rows were affected\n",
    "    print(f\"Updated {result.rowcount} row(s)\")\n",
    "\n",
    "# Query to verify the update worked\n",
    "df = pd.read_sql(\"SELECT * FROM students WHERE email = 'john.doe@example.com';\", engine)\n",
    "print(\"\\nUpdated student record:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26fa07d",
   "metadata": {},
   "source": [
    "### Update Multiple Records\n",
    "\n",
    "You can update many rows at once using a WHERE clause that matches multiple records. This is useful for:\n",
    "- Batch updates based on conditions\n",
    "- Changing status flags for groups of records\n",
    "- Applying business rules to multiple rows\n",
    "\n",
    "The WHERE clause can use comparison operators: `=`, `<`, `>`, `<=`, `>=`, `!=`, `BETWEEN`, `IN`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c647f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2 row(s)\n",
      "\n",
      "All students after update:\n",
      "   student_id first_name last_name                       email  \\\n",
      "0           1       John       Doe        john.doe@example.com   \n",
      "1           2       Jane     Smith      jane.smith@example.com   \n",
      "2           3        Bob   Johnson     bob.johnson@example.com   \n",
      "3           4      Alice  Williams  alice.williams@example.com   \n",
      "4           5    Charlie     Brown   charlie.brown@example.com   \n",
      "\n",
      "  enrollment_date   gpa  is_active                 created_at  \n",
      "0      2025-10-30  3.95       True 2025-10-30 02:50:15.348302  \n",
      "1      2025-10-30  3.90       True 2025-10-30 02:50:15.361754  \n",
      "2      2025-10-30  3.45      False 2025-10-30 02:50:15.361754  \n",
      "3      2025-10-30  3.85       True 2025-10-30 02:50:15.361754  \n",
      "4      2025-10-30  3.20      False 2025-10-30 02:50:15.361754  \n"
     ]
    }
   ],
   "source": [
    "# Define SQL to update multiple students based on a condition\n",
    "update_multiple_sql = \"\"\"\n",
    "UPDATE students                                  -- Table to update\n",
    "SET is_active = FALSE                            -- Set is_active to FALSE\n",
    "WHERE gpa < 3.50;                                -- For all students with GPA below 3.50\n",
    "\"\"\"\n",
    "# This will update Bob (3.45) and Charlie (3.20), but not Jane (3.90), Alice (3.85), or John (3.95)\n",
    "\n",
    "# Execute the UPDATE statement\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(update_multiple_sql))\n",
    "    connection.commit()  # Commit the changes\n",
    "    # rowcount tells us how many rows matched the WHERE condition\n",
    "    print(f\"Updated {result.rowcount} row(s)\")\n",
    "\n",
    "# Query all students to see the results of our batch update\n",
    "df = pd.read_sql(\"SELECT * FROM students ORDER BY student_id;\", engine)\n",
    "print(\"\\nAll students after update:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476777dc",
   "metadata": {},
   "source": [
    "## 4. Uploading Data from a CSV File\n",
    "\n",
    "CSV (Comma-Separated Values) files are a common format for storing tabular data. We can easily import CSV data into PostgreSQL tables using pandas.\n",
    "\n",
    "**Process:**\n",
    "1. Read the CSV file using pandas (`pd.read_csv()`)\n",
    "2. Create a table structure (or let pandas create it automatically)\n",
    "3. Use pandas' `to_sql()` method to upload the data\n",
    "\n",
    "**Benefits:**\n",
    "- Fast bulk data loading\n",
    "- Handles data type conversion automatically\n",
    "- Works with large datasets\n",
    "- Can update existing tables or create new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f201471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CSV file created at: /workspaces/Fall2025-MS3083-Base_Template/databases/sample_courses.csv\n",
      "\n",
      "CSV file contents:\n",
      "  course_code                       course_name  credits        department\n",
      "0       CS101  Introduction to Computer Science        3  Computer Science\n",
      "1     MATH201                        Calculus I        4       Mathematics\n",
      "2      ENG101               English Composition        3           English\n",
      "3     PHYS101                   General Physics        4           Physics\n",
      "4     HIST201                     World History        3           History\n"
     ]
    }
   ],
   "source": [
    "# First, let's create a sample CSV file for demonstration\n",
    "import csv\n",
    "\n",
    "# Define the path where we'll save the CSV file\n",
    "csv_file_path = '/workspaces/Fall2025-MS3083-Base_Template/databases/sample_courses.csv'\n",
    "\n",
    "# Create sample course data as a list of lists\n",
    "# First row contains column headers, remaining rows contain data\n",
    "course_data = [\n",
    "    ['course_code', 'course_name', 'credits', 'department'],                  # Header row\n",
    "    ['CS101', 'Introduction to Computer Science', 3, 'Computer Science'],     # Data row 1\n",
    "    ['MATH201', 'Calculus I', 4, 'Mathematics'],                              # Data row 2\n",
    "    ['ENG101', 'English Composition', 3, 'English'],                          # Data row 3\n",
    "    ['PHYS101', 'General Physics', 4, 'Physics'],                             # Data row 4\n",
    "    ['HIST201', 'World History', 3, 'History']                                # Data row 5\n",
    "]\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)  # Create a CSV writer object\n",
    "    writer.writerows(course_data)  # Write all rows at once\n",
    "\n",
    "print(f\"Sample CSV file created at: {csv_file_path}\")\n",
    "\n",
    "# Read the CSV file using pandas to verify it was created correctly\n",
    "df_csv = pd.read_csv(csv_file_path)\n",
    "print(\"\\nCSV file contents:\")\n",
    "print(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039eab8",
   "metadata": {},
   "source": [
    "### Upload CSV Data to PostgreSQL Table\n",
    "\n",
    "Now we'll create a table and import the CSV data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a1a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'courses' created successfully!\n",
      "Uploaded 5 rows from CSV to 'courses' table\n",
      "\n",
      "Data in courses table:\n",
      "  course_code                       course_name  credits        department\n",
      "0       CS101  Introduction to Computer Science        3  Computer Science\n",
      "1      ENG101               English Composition        3           English\n",
      "2     HIST201                     World History        3           History\n",
      "3     MATH201                        Calculus I        4       Mathematics\n",
      "4     PHYS101                   General Physics        4           Physics\n"
     ]
    }
   ],
   "source": [
    "# Define the table structure for courses\n",
    "create_courses_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS courses (\n",
    "    course_code VARCHAR(20) PRIMARY KEY,          -- Course code (e.g., CS101) - unique identifier\n",
    "    course_name VARCHAR(200) NOT NULL,            -- Full course name (required)\n",
    "    credits INTEGER CHECK (credits > 0),          -- Number of credits (must be positive)\n",
    "    department VARCHAR(100) NOT NULL              -- Department offering the course\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Create the table in the database\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(create_courses_table))\n",
    "    connection.commit()\n",
    "    print(\"Table 'courses' created successfully!\")\n",
    "\n",
    "# Now upload the CSV data to the table using pandas\n",
    "# if_exists='append' means: add to existing data (don't replace or fail)\n",
    "# index=False means: don't insert the DataFrame index as a column\n",
    "df_csv.to_sql('courses', engine, if_exists='append', index=False)\n",
    "print(f\"Uploaded {len(df_csv)} rows from CSV to 'courses' table\")\n",
    "\n",
    "# Verify the data was uploaded correctly\n",
    "df_verify = pd.read_sql(\"SELECT * FROM courses ORDER BY course_code;\", engine)\n",
    "print(\"\\nData in courses table:\")\n",
    "print(df_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bb372",
   "metadata": {},
   "source": [
    "### Upload Your Own CSV File\n",
    "\n",
    "Use this cell to upload data from your own CSV file. This is a template you can customize for any CSV file you want to import.\n",
    "\n",
    "**Instructions:**\n",
    "1. Update the `csv_file_path` variable with the path to your CSV file\n",
    "2. Update the `table_name` variable with your desired table name\n",
    "3. Run the cell to create the table and import the data\n",
    "\n",
    "**Options for `if_exists` parameter:**\n",
    "- `'fail'`: Raise an error if table already exists (safest)\n",
    "- `'replace'`: Drop the existing table and create a new one (destructive!)\n",
    "- `'append'`: Add data to existing table (most common for data loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce6706",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspaces/Fall2025-MS3083-Base_Template/databases/your_file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m table_name = \u001b[33m'\u001b[39m\u001b[33myour_table_name\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ======================================\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_custom = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCSV file loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_custom)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFirst few rows:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/Fall2025-MS3083-Base_Template/databases/your_file.csv'"
     ]
    }
   ],
   "source": [
    "# ===== CUSTOMIZE THESE VARIABLES =====\n",
    "csv_file_path = '/workspaces/Fall2025-MS3083-Base_Template/databases/your_file.csv'  # Path to your CSV file\n",
    "table_name = 'your_table_name'  # Name for the table in PostgreSQL\n",
    "# ======================================\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df_custom = pd.read_csv(csv_file_path)\n",
    "print(f\"CSV file loaded: {len(df_custom)} rows\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_custom.head())  # Show first 5 rows to verify data\n",
    "\n",
    "# Upload the DataFrame to PostgreSQL\n",
    "# if_exists options: 'fail', 'replace', 'append'\n",
    "# 'replace' will drop the existing table and create a new one\n",
    "df_custom.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "print(f\"\\nData uploaded to table '{table_name}'\")\n",
    "\n",
    "# Verify the upload by querying the first 10 rows\n",
    "df_verify = pd.read_sql(f\"SELECT * FROM {table_name} LIMIT 10;\", engine)\n",
    "print(f\"\\nFirst 10 rows from '{table_name}' table:\")\n",
    "print(df_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b30bf",
   "metadata": {},
   "source": [
    "## 5. Paste LucidChart Exported SQL\n",
    "\n",
    "LucidChart is a popular tool for designing database schemas visually. It can export your database design as SQL code, which you can then paste here to create all your tables at once.\n",
    "\n",
    "**Instructions:**\n",
    "1. In LucidChart, design your database schema (tables, columns, relationships)\n",
    "2. Export your schema: File → Export → SQL (PostgreSQL format recommended)\n",
    "3. Copy the exported SQL code\n",
    "4. Paste it in the `lucidchart_sql` variable below (between the triple quotes)\n",
    "5. Run the cell to create all tables\n",
    "\n",
    "**What this cell does:**\n",
    "- Splits the SQL by semicolons to execute each statement separately\n",
    "- Skips comment lines (starting with --)\n",
    "- Creates all tables defined in your LucidChart diagram\n",
    "- Shows you a list of all tables created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PASTE YOUR LUCIDCHART SQL CODE BELOW =====\n",
    "lucidchart_sql = \"\"\"\n",
    "-- Paste your LucidChart exported SQL here\n",
    "-- Example:\n",
    "-- CREATE TABLE departments (\n",
    "--     dept_id SERIAL PRIMARY KEY,\n",
    "--     dept_name VARCHAR(100) NOT NULL\n",
    "-- );\n",
    "-- \n",
    "-- CREATE TABLE employees (\n",
    "--     emp_id SERIAL PRIMARY KEY,\n",
    "--     first_name VARCHAR(50),\n",
    "--     last_name VARCHAR(50),\n",
    "--     dept_id INTEGER REFERENCES departments(dept_id)\n",
    "-- );\n",
    "\"\"\"\n",
    "# ==================================================\n",
    "\n",
    "# Execute the SQL code\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        # Split the SQL by semicolons to get individual statements\n",
    "        statements = [stmt.strip() for stmt in lucidchart_sql.split(';') if stmt.strip()]\n",
    "        \n",
    "        # Execute each statement one at a time\n",
    "        for statement in statements:\n",
    "            # Skip empty statements and comments\n",
    "            if statement and not statement.startswith('--'):\n",
    "                connection.execute(text(statement))  # Execute the CREATE TABLE statement\n",
    "        \n",
    "        connection.commit()  # Commit all changes at once\n",
    "        print(\"LucidChart SQL executed successfully!\")\n",
    "    \n",
    "    # Query PostgreSQL's system tables to show all user-created tables\n",
    "    tables_query = \"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'    -- 'public' is the default schema\n",
    "    ORDER BY table_name;\n",
    "    \"\"\"\n",
    "    df_tables = pd.read_sql(tables_query, engine)\n",
    "    print(\"\\nAll tables in the database:\")\n",
    "    print(df_tables)\n",
    "    \n",
    "except Exception as e:\n",
    "    # If anything goes wrong, show the error message\n",
    "    print(f\"Error executing SQL: {e}\")\n",
    "    print(\"\\nMake sure to paste valid SQL code in the lucidchart_sql variable above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ff84d",
   "metadata": {},
   "source": [
    "## 6. Additional Operations\n",
    "\n",
    "### Drop a Table (Use with Caution!)\n",
    "\n",
    "The DROP TABLE command permanently deletes a table and **ALL its data**. This action cannot be undone!\n",
    "\n",
    "**When to use DROP TABLE:**\n",
    "- Removing test tables\n",
    "- Cleaning up old/unused tables\n",
    "- Starting fresh with a new table structure\n",
    "\n",
    "**Safety tips:**\n",
    "- ALWAYS double-check the table name before executing\n",
    "- Use `DROP TABLE IF EXISTS` to avoid errors if table doesn't exist\n",
    "- Consider backing up data before dropping tables\n",
    "- This code is commented out by default to prevent accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Drop a table (be very careful with this!)\n",
    "drop_table_sql = \"\"\"\n",
    "-- DROP TABLE IF EXISTS table_name;  -- Replace 'table_name' with actual table to drop\n",
    "\"\"\"\n",
    "# IF EXISTS prevents errors if the table doesn't exist\n",
    "# Without IF EXISTS, you'd get an error if the table isn't there\n",
    "\n",
    "# The code below is commented out for safety\n",
    "# To use it:\n",
    "# 1. Replace 'table_name' in the SQL above with your actual table name\n",
    "# 2. Uncomment the lines below by removing the # symbols\n",
    "# 3. Run the cell\n",
    "\n",
    "# with engine.connect() as connection:\n",
    "#     connection.execute(text(drop_table_sql))\n",
    "#     connection.commit()\n",
    "#     print(\"Table dropped successfully!\")\n",
    "\n",
    "print(\"To drop a table, uncomment the code above and specify the table name.\")\n",
    "print(\"WARNING: Dropping a table permanently deletes all data. This cannot be undone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365135f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
